<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="title"
    content="P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation">
  <meta name="description"
    content="P²Fusion is a prompt-based fusion framework that integrates dual complementary priors via distillation-based learnable prompts for state-of-the-art infrared-visible image fusion.">
  <meta name="keywords"
    content="Infrared-Visible Image Fusion, IVIF, Deep Learning, Computer Vision, Prompt Learning, Distillation">
  <meta name="author"
    content="Yi Shi, Huichao Xie, Yuqing Wang, Kai Zheng, Teng Yang, Yu Liu, Junwei Han, Dingwen Zhang">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="P²Fusion Project">
  <meta property="og:title"
    content="P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation">
  <meta property="og:description"
    content="P²Fusion is a prompt-based fusion framework that integrates dual complementary priors via distillation-based learnable prompts for state-of-the-art infrared-visible image fusion.">
  <meta property="og:url" content="https://p2fusion.github.io/">
  <meta property="og:image" content="static/images/social_preview.png">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title"
    content="P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation">
  <meta name="twitter:description"
    content="P²Fusion is a prompt-based fusion framework that integrates dual complementary priors via distillation-based learnable prompts for state-of-the-art infrared-visible image fusion.">
  <meta name="twitter:image" content="static/images/social_preview.png">

  <!-- Academic/Research Specific -->
  <meta name="citation_title"
    content="P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation">
  <meta name="citation_author" content="Shi, Yi">
  <meta name="citation_author" content="Xie, Huichao">
  <meta name="citation_publication_date" content="2024">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css?v=1.0">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js?v=1.0"></script>

  <!-- Model Viewer for 3D models -->
  <script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.3.0/model-viewer.min.js"></script>

  <!-- Inline script to ensure switchModel is available globally -->
  <script>
    window.switchModel = function (modelName) {
      const modelViewer = document.getElementById('model-viewer');
      const buttons = document.querySelectorAll('.model-switch-btn');

      if (modelViewer) {
        modelViewer.src = `static/3d/${modelName}.glb`;
        buttons.forEach(btn => {
          if (btn.getAttribute('data-model') === modelName) {
            btn.classList.add('active');
          } else {
            btn.classList.remove('active');
          }
        });
      }
    };
  </script>
</head>

<body>

  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                <span style="color: #2563eb;">P<sup>2</sup>Fusion</span>: Prompt-based Progressive Infrared-Visible
                Image Fusion via Dual-Prior Distillation
              </h1>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Yi Shi<sup>1</sup>,</span>
                <span class="author-block">Huichao Xie<sup>1</sup>,</span>
                <span class="author-block">Yuqing Wang<sup>1</sup>,</span>
                <span class="author-block">Kai Zheng<sup>1</sup>,</span>
                <span class="author-block">Teng Yang<sup>1</sup>,</span>
                <span class="author-block">Yu Liu<sup>2</sup>,</span>
                <span class="author-block">Junwei Han<sup>1</sup>,</span>
                <span class="author-block">Dingwen Zhang<sup>1</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Northwestern Polytechnical University, <br>
                  <sup>2</sup>Hefei University of Technology</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Paper Link -->
                  <span class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary Link -->
                  <span class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Code Link -->
                  <span class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- arXiv Link -->
                  <span class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Teaser Image -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <figure class="teaser-illustration">
            <img src="static/images/main.svg" alt="P2Fusion Teaser" style="width: 100%; height: auto;">
          </figure>
          <figcaption class="has-text-justified has-text-grey">
            Compared with existing IVIF methods, P²Fusion uses two complementary priors to provide dynamic prompt-based
            guidance during optimization, alleviating gradient conflicts, achieving better performance on various
            fusion, segmentation, and detection metrics on MSRS, and producing clearer textures, more stable modality
            balance, and more consistent downstream results.
          </figcaption>
        </div>
      </div>
    </section>
    <!-- End Teaser Image -->

    <!-- Abstract -->
    <section class="section themed-section theme-bg-1" id="abstract">
      <div class="section-inner">
        <div class="section-heading has-text-centered">
          <h2 class="title is-3">Abstract</h2>
        </div>
        <div class="content has-text-justified">
          <p>
            Infrared-visible image fusion (IVIF) aims to generate a single image that preserves complementary
            information from both modalities, serving as a critical component in multimodal perception. Although
            prior-guided fusion methods have achieved notable progress, existing approaches commonly inject priors as
            static constraints or penalty terms, limiting generalization and inducing multi-task optimization conflicts.
            To address these limitations, we propose P<sup>2</sup>Fusion, a prompt-based fusion framework that
            integrates dual complementary priors—a thermal-saliency prior to capture infrared target semantics and a
            spatial-quality-distribution prior to encode visible reliability—via distillation-based learnable prompts.
            Unlike conventional hard-coded priors, both priors are distilled from dedicated teachers (infrared-saliency
            and visible-quality) into dynamic prompts that condition the fusion process procedurally rather than as
            fixed penalties, enabling context-adaptive modulation and improved generalization. Crucially, we introduce a
            perceptual-adaptation mechanism that explicitly prescribes how these dual priors are loaded, weighted, and
            coordinated throughout the fusion pipeline, thereby preventing prior dominance and avoiding multi-task
            conflicts. Guided by this dual-prior framework, we design a Dual-Granularity Progressive Fusion (DGPF)
            module that refines features from coarse, prior-aligned aggregation to fine-grained, prior-conditioned
            fusion. Extensive experiments across diverse benchmarks validate P<sup>2</sup>Fusion’s superiority. On MSRS,
            it achieves SOTA on five of seven fusion metrics. For downstream tasks, P²Fusion further improves over the
            fusion baselines by +3.6% mAP on object detection and +0.401% mIoU on semantic segmentation, demonstrating
            its superior fusion quality and strong utility for subsequent perception tasks.
          </p>
        </div>
      </div>
    </section>
    <!-- End Abstract -->


    <!-- Overview -->
    <section class="section themed-section theme-bg-2" id="overview">
      <div class="section-inner has-text-centered">
        <div class="section-heading">
          <h2 class="title is-3">Overview</h2>
        </div>
        <figure>
          <img src="static/images/net.svg" alt="Overview of the P2Fusion framework" style="width: 100%; height: auto;">
          <figcaption class="has-text-justified has-text-grey">
            The overall framework of our proposed P<sup>2</sup>Fusion. The core network comprises dual-teacher
            distillation and a DGPF module. Dual priors are embedded into DGPF as prompts to guide dynamic, adaptive
            iterative updates of fused features. Specific architectural details are in the inset subfigures.
          </figcaption>
        </figure>
      </div>
    </section>
    <!-- End Overview -->


    <!-- Main Results -->
    <section class="section themed-section theme-bg-3" id="main-results">
      <div class="section-inner has-text-centered">
        <div class="section-heading">
          <h2 class="title is-3">Main Results</h2>
        </div>
        <figure>
          <img src="static/images/res.png" alt="Main results of P2Fusion" style="width: 100%; height: auto;">
        </figure>
      </div>
    </section>
    <!-- End Main Results -->


    <!-- Visualization -->
    <section class="section themed-section theme-bg-4 visualization-section" id="visualization">
      <div class="section-inner has-text-centered">
        <div class="section-heading">
          <h2 class="title is-3">Visualization</h2>
        </div>
        <figure class="mb-6">
          <img src="static/images/fusion.svg" alt="Qualitative comparison across diverse scenes"
            style="width: 100%; height: auto;">
          <figcaption class="has-text-justified has-text-grey">
            Qualitative comparison between our P<sup>2</sup>Fusion and existing image fusion methods. From top to
            bottom: well-lit scenes from M3FD, smoke-occluded scenes from FMB, and over-exposed scenes from RoadScene.
          </figcaption>
        </figure>
        <figure>
          <img src="static/images/det&seg.svg" alt="Detection and segmentation qualitative comparison"
            style="width: 100%; height: auto;">
          <figcaption class="has-text-justified has-text-grey">
            Qualitative comparison of P<sup>2</sup>Fusion against other fusion methods on the downstream object
            detection task (M3FD) and the semantic segmentation task (FMB); P<sup>2</sup>Fusion consistently
            demonstrates superior performance.
          </figcaption>
        </figure>

        <div class="visualization-subsection" id="fusion-gallery">
          <h3 class="title is-4 mt-6">Fusion Images</h3>
          <div class="fusion-carousel-shell">
            <button class="fusion-nav-btn" id="fusionPrev" aria-label="Previous slide">
              <span class="icon"><i class="fas fa-chevron-left"></i></span>
            </button>
            <div class="fusion-carousel">
              <div class="fusion-carousel-track" id="fusionCarouselTrack"></div>
            </div>
            <button class="fusion-nav-btn" id="fusionNext" aria-label="Next slide">
              <span class="icon"><i class="fas fa-chevron-right"></i></span>
            </button>
          </div>
          <div class="fusion-carousel-dots" id="fusionCarouselDots" role="tablist"></div>
        </div>

        <div class="visualization-subsection" id="depth-gallery">
          <h3 class="title is-4 mt-6">Depth Images</h3>
          <div class="depth-header">
            <span class="depth-filename" id="depthActiveName"></span>
          </div>
          <div class="fusion-carousel-shell depth-carousel-shell">
            <button class="fusion-nav-btn" id="depthPrev" aria-label="Previous depth pair">
              <span class="icon"><i class="fas fa-chevron-left"></i></span>
            </button>
            <div class="depth-carousel">
              <div class="depth-carousel-track" id="depthCarouselTrack"></div>
            </div>
            <button class="fusion-nav-btn" id="depthNext" aria-label="Next depth pair">
              <span class="icon"><i class="fas fa-chevron-right"></i></span>
            </button>
          </div>
          <div class="fusion-carousel-dots" id="depthCarouselDots" role="tablist"></div>
        </div>

        <div class="visualization-subsection" id="model-viewer-section">
          <h3 class="title is-4 mt-6">3D Model</h3>
          <div class="model-switch-container">
            <button class="model-switch-btn active" onclick="switchModel('vi')" data-model="vi">
              VI
            </button>
            <button class="model-switch-btn" onclick="switchModel('ir')" data-model="ir">
              IR
            </button>
            <button class="model-switch-btn" onclick="switchModel('mrfs')" data-model="mrfs">
              MRFS
            </button>
            <button class="model-switch-btn" onclick="switchModel('sage')" data-model="sage">
              SAGE
            </button>
            <button class="model-switch-btn" onclick="switchModel('timfusion')" data-model="timfusion">
              TIM
            </button>
            <button class="model-switch-btn" onclick="switchModel('ours')" data-model="ours">
              Ours
            </button>
          </div>
          <model-viewer id="model-viewer" src="static/3d/vi/3d/vi.glb" alt="3D Model" auto-rotate camera-controls
            interaction-policy="allow-when-focused" style="width: 100%; height: 600px; background-color: #f5f5f5;">
          </model-viewer>
        </div>
      </div>
    </section>
    <!-- End Visualization -->

    <!-- BibTeX -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title is-3">BibTeX</h2>
        </div>
        <pre><code>@article{Shi2024P2Fusion,
  title={P²Fusion: Prompt-based Progressive Infrared-Visible Image Fusion via Dual-Prior Distillation},
  author={Shi, Yi and Xie, Huichao and Wang, Yuqing and Zheng, Kai and Yang, Teng and Liu, Yu and Han, Junwei and Zhang, Dingwen},
  journal={Conference/Journal Name},
  year={2024}
}</code></pre>
      </div>
    </section>
    <!-- End BibTeX -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content has-text-centered">
              <p>
                This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

</body>

</html>